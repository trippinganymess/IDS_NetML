
\begin{table}[htbp]
\centering
\caption{Classification Performance Comparison on NetML-2020 Dataset}
\label{tab:results}
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{LSTM-Attn} & \textbf{+ XGBoost} & \textbf{+ Ensemble} \\
                & \textbf{(Softmax)} & & \textbf{(Best)} \\
\midrule
Macro F1        & 0.5103 & 0.5243 (+2.74\%) & \textbf{0.5332 (+4.49\%)} \\
Weighted F1     & 0.7752 & 0.7619 & 0.7662 \\
Accuracy        & 78.68\% & 76.07\% & 76.10\% \\
\midrule
\multicolumn{4}{l}{\textit{High-F1 Classes (F1 $\geq$ 0.90)}} \\
\quad Maintained & 6/6 & 5/6 & 6/6 \\
\midrule
\multicolumn{4}{l}{\textit{Zero-Recall Classes (Baseline F1 = 0)}} \\
\quad CCleaner      & 0.00 & 0.63 & \textbf{0.64} \\
\quad Trickster     & 0.00 & 0.27 & \textbf{0.35} \\
\quad MagicHound    & 0.00 & 0.07 & \textbf{0.10} \\
\quad WebCompanion  & 0.00 & 0.06 & \textbf{0.09} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Validation set: 70,000 samples (20\% of NetML-2020), 21 traffic classes.
\item Ensemble: LightGBM + Random Forest with weighted voting.
\end{tablenotes}
\end{table}
